{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: update ping (reason = success) validation on Nightly\n",
    "authors:\n",
    "- dexter\n",
    "tags:\n",
    "- firefox\n",
    "- update\n",
    "- latency\n",
    "created_at: 2016-09-14\n",
    "updated_at: 2016-09-14\n",
    "tldr: This notebook verifies that the `update` ping with `reason = success` behaves as expected on Nightly.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate 'update' ping submissions on Nightly (`reason = success`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis validates the `update` ping with `reason = success`, which was introduced in [bug 1380256](https://bugzilla.mozilla.org/show_bug.cgi?id=1380256) and should be sent every time an update is applied after the browser is restarted. We are going to verify that:\n",
    "\n",
    "- the ping is received within a reasonable time after the browser is started;\n",
    "- we receive one ping per update;\n",
    "- that the payload looks ok;\n",
    "- check if the volume of update pings is within the expected range by cross-checking it with the update ping with `reason = ready`;\n",
    "- that we don't receive many duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ujson as json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "import IPython\n",
    "\n",
    "from plotly.graph_objs import *\n",
    "from moztelemetry import get_pings_properties, get_one_ping_per_client\n",
    "from moztelemetry.dataset import Dataset\n",
    "from datetime import datetime, timedelta\n",
    "from email.utils import parsedate_tz, mktime_tz, formatdate\n",
    "\n",
    "%matplotlib inline\n",
    "IPython.core.pylabtools.figsize(16, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `update` ping with `reason = success` landed on the Nightly channel on the 1st of September, 2017. Let's get the first full-week of data after that date: 3rd-9th September, 2017. Restrict to the data coming from the Nightly builds after the day the ping landed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MIN_DATE = \"20170903\"\n",
    "MAX_DATE = \"20170910\"\n",
    "\n",
    "update_pings = Dataset.from_source(\"telemetry\") \\\n",
    "    .where(docType=\"update\") \\\n",
    "    .where(appUpdateChannel=\"nightly\") \\\n",
    "    .where(submissionDate=lambda x: MIN_DATE <= x < MAX_DATE) \\\n",
    "    .where(appBuildId=lambda x: MIN_DATE <= x < MAX_DATE) \\\n",
    "    .records(sc, sample=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some misc functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pct(a, b):\n",
    "    return 100.0 * a / b\n",
    "\n",
    "def dedupe(pings, duping_key):\n",
    "    return pings\\\n",
    "            .map(lambda p: (p[duping_key], p))\\\n",
    "            .reduceByKey(lambda a, b: a if a[\"meta/Timestamp\"] < b[\"meta/Timestamp\"] else b)\\\n",
    "            .map(lambda pair: pair[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misc functions to plot the CDF of the submission delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_DELAY_S = 60 * 60 * 96.0\n",
    "HOUR_IN_S = 60 * 60.0\n",
    "\n",
    "def setup_plot(title, max_x, area_border_x=0.1, area_border_y=0.1):\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Delay (hours)\")\n",
    "    plt.ylabel(\"% of pings\")\n",
    "\n",
    "    plt.xticks(range(0, int(max_x) + 1, 2))\n",
    "    plt.yticks(map(lambda y: y / 20.0, range(0, 21, 1)))\n",
    "\n",
    "    plt.ylim(0.0 - area_border_y, 1.0 + area_border_y)\n",
    "    plt.xlim(0.0 - area_border_x, max_x + area_border_x)\n",
    "\n",
    "    plt.grid(True)\n",
    "\n",
    "def plot_cdf(data, **kwargs):\n",
    "    sortd = np.sort(data)\n",
    "    ys = np.arange(len(sortd))/float(len(sortd))\n",
    "\n",
    "    plt.plot(sortd, ys, **kwargs)\n",
    "    \n",
    "def calculate_submission_delay(p):\n",
    "    created = datetime.fromtimestamp(p[\"meta/creationTimestamp\"] / 1000.0 / 1000.0 / 1000.0)\n",
    "    received = datetime.fromtimestamp(p[\"meta/Timestamp\"] / 1000.0 / 1000.0 / 1000.0)\n",
    "    sent = datetime.fromtimestamp(mktime_tz(parsedate_tz(p[\"meta/Date\"]))) if p[\"meta/Date\"] is not None else received\n",
    "    clock_skew = received - sent\n",
    "\n",
    "    return (received - created - clock_skew).total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the ping payload\n",
    "Check that the payload section contains the right entries with consistent values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset = get_pings_properties(update_pings, [\"id\",\n",
    "                                             \"clientId\",\n",
    "                                             \"meta/creationTimestamp\",\n",
    "                                             \"meta/Date\",\n",
    "                                             \"meta/Timestamp\",\n",
    "                                             \"application/buildId\",\n",
    "                                             \"application/channel\",\n",
    "                                             \"application/version\",\n",
    "                                             \"environment/system/os/name\",\n",
    "                                             \"payload/reason\",\n",
    "                                             \"payload/targetBuildId\",\n",
    "                                             \"payload/targetChannel\",\n",
    "                                             \"payload/targetVersion\",\n",
    "                                             \"payload/previousBuildId\",\n",
    "                                             \"payload/previousChannel\",\n",
    "                                             \"payload/previousVersion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ping_success = subset.filter(lambda p: p.get(\"payload/reason\") == \"success\")\n",
    "ping_ready = subset.filter(lambda p: p.get(\"payload/reason\") == \"ready\")\n",
    "\n",
    "ping_success_count = ping_success.count()\n",
    "ping_ready_count = ping_ready.count()\n",
    "ping_count = ping_ready_count + ping_success_count\n",
    "# As a safety precaution, assert that we only received the\n",
    "# reasons we were looking for.\n",
    "assert ping_count == subset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantify the percentage of duplicate pings we're receiving. We don't expect this value to be greater than ~1%, which is the amount we usually get from `main` and `crash`: as a rule of thumb, we threat anything less than 1% as *probably* well behaving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deduped_subset = dedupe(ping_success, \"id\")\n",
    "deduped_count = deduped_subset.count()\n",
    "print(\"Percentage of duplicate pings: {:.3f}\".format(100.0 - pct(deduped_count, ping_success_count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percentage of duplicate pings is within the expected range. Move on and verify the payload of the `update` pings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validate_update_payload(p):\n",
    "    PAYLOAD_KEYS = [\n",
    "        \"payload/reason\",\n",
    "        \"payload/previousBuildId\",\n",
    "        \"payload/previousChannel\",\n",
    "        \"payload/previousVersion\"\n",
    "    ]\n",
    "\n",
    "    # All the payload keys needs to be strings.\n",
    "    for k in PAYLOAD_KEYS:\n",
    "        if not isinstance(p.get(k), basestring):\n",
    "            return (\"'{}' is not a string\".format(k), 1)\n",
    "        \n",
    "    # For Nightly, the previous channel should be the same as the\n",
    "    # application channel.\n",
    "    if p.get(\"payload/previousChannel\") != p.get(\"application/channel\"):\n",
    "        return (\"Previous channel mismatch: expected {} got {}\"\\\n",
    "                .format(p.get(\"payload/previousChannel\"), p.get(\"application/channel\")), 1)\n",
    "                \n",
    "    # The previous buildId must be smaller than the application build id.\n",
    "    if p.get(\"payload/previousBuildId\") > p.get(\"application/buildId\"):\n",
    "        return (\"Previous buildId mismatch: {} must be older than {}\"\\\n",
    "                .format(p.get(\"payload/previousBuildId\"), p.get(\"application/buildId\")), 1)\n",
    "    \n",
    "    return (\"Ok\", 1)\n",
    "\n",
    "validation_results = deduped_subset.map(validate_update_payload).countByKey()\n",
    "for k, v in sorted(validation_results.iteritems()):\n",
    "    print(\"{}:\\t{:.3f}%\".format(k, pct(v, ping_success_count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vast majority of the data in the payload seems reasonable (99.87%).\n",
    "\n",
    "However, a handful of `update` pings are reporting a `previousBuildId` mismatch: this is unexpected. **After discussing this with the *update team*, it seems like this could either be due to Nigthly channel weirdness or to the customization applied by the [CCK tool](https://mike.kaply.com/cck2/).** Additionally, some pings are reporting a `previousChannel` different than the one in the environment: this is definitely due to the CCK tool, given the *cck* entry in the channel name. These issues do not represent a problem, as most of the data is correct and their volume is fairly low.\n",
    "\n",
    "## Check that we receive one ping per client and target update\n",
    "For each ping, build a key with the client id and the previous build update details. Since we expect to have exactly one ping for each successfully applied *update*, we don't expect duplicate keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "update_dupes = deduped_subset.map(lambda p: ((p.get(\"clientId\"),\n",
    "                                              p.get(\"payload/previousChannel\"),\n",
    "                                              p.get(\"payload/previousVersion\"),\n",
    "                                              p.get(\"payload/previousBuildId\")), 1)).countByKey()\n",
    "\n",
    "print(\"Percentage of pings related to the same update (for the same client):\\t{:.3f}%\"\\\n",
    "      .format(pct(sum([v for v in update_dupes.values() if v > 1]), deduped_count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're receiving `update` pings with different `documentId` related to the same initial build, for a few clients. One possible reason for this could be users having multiple copies of Firefox installed on their machine. Let's see if that's the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clientIds_sending_dupes = [k[0] for k, v in update_dupes.iteritems() if v > 1]\n",
    "\n",
    "def check_same_original_build(ping_list):\n",
    "    # Build a \"unique\" identifier for the build by\n",
    "    # concatenating the buildId, channel and version.\n",
    "    unique_build_ids = [\n",
    "        \"{}{}{}\".format(p.get(\"application/buildId\"), p.get(\"application/channel\"), p.get(\"application/version\"))\\\n",
    "        for p in ping_list[1]\n",
    "    ]\n",
    "    \n",
    "    # Remove the duplicates and return True if all the pings came\n",
    "    # from the same build.\n",
    "    return len(set(unique_build_ids)) < 2\n",
    "    \n",
    "# Count how many duplicates are updating to the same builds and how many are\n",
    "# updating to different builds.\n",
    "original_builds_same =\\\n",
    "    deduped_subset.filter(lambda p: p.get(\"clientId\") in clientIds_sending_dupes)\\\n",
    "                  .map(lambda p: ((p.get(\"clientId\"),\n",
    "                                   p.get(\"payload/previousChannel\"),\n",
    "                                   p.get(\"payload/previousVersion\"),\n",
    "                                   p.get(\"payload/previousBuildId\")), [p]))\\\n",
    "                  .reduceByKey(lambda a, b: a + b)\\\n",
    "                  .filter(lambda p: len(p[1]) > 1)\\\n",
    "                  .map(check_same_original_build).countByValue()\n",
    "                    \n",
    "print(\"Updated builds are identical:\\t{:.3f}%\"\\\n",
    "      .format(pct(original_builds_same.get(True), sum(original_builds_same.values()))))\n",
    "print(\"Updated builds are different:\\t{:.3f}%\"\\\n",
    "      .format(pct(original_builds_same.get(False), sum(original_builds_same.values()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data shows that 83.52% of the 1.31% dupes are updating from different builds. The 0.22% of all `update` pings that are the same client updating to the same build from the same build are, at present, unexplained (but in small enough quantities we can ignore for the moment).\n",
    "\n",
    "The `update` pings with the same previous build information may be coming from the same profile, copied and then used with different versions of Firefox. Depending on when the browser is started with a specific copied profile, the downloaded *update* blob might be different (more recent), thus resulting in an `update` with `reason = success` being sent with the same *previous build* information but with different *current build* information.\n",
    "\n",
    "## Validate the submission delay\n",
    "\n",
    "### How long until we receive the ping after it's created?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delays = deduped_subset.map(lambda p: calculate_submission_delay(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setup_plot(\"'update' ('success') ping submission delay CDF\",\n",
    "           MAX_DELAY_S / HOUR_IN_S, area_border_x=1.0)\n",
    "\n",
    "plot_cdf(delays\\\n",
    "         .map(lambda d: d / HOUR_IN_S if d < MAX_DELAY_S else MAX_DELAY_S / HOUR_IN_S)\\\n",
    "         .collect(), label=\"CDF\", linestyle=\"solid\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Almost 95% of the `update` pings with `reason = success` are submitted within an hour from the ping being created. Since we know that this ping is created as soon as the [update is applied](https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/update-ping.html#payload-reason) we can claim that we receive 95% of these pings within an hour from the update being applied. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure that the volume of incoming pings is reasonable\n",
    "Check if the volume of `update` pings with `reason = ready` matches with the volume of pings with `reason = success`. For each ping with `reason = ready`, find the matching ping with `reason = success`.\n",
    "\n",
    "We are considering the data within a very narrow window of time: we could see `reason = success` pings from users that sent a `reason = ready` ping before the 3rd of September and `reason = ready` pings from users that have sent us a `reason = success` after the 9th of September. Filter these edge cases out by inspecting the `previousBuildId` and `targetBuildId`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_ready = ping_ready.filter(lambda p: p.get(\"payload/targetBuildId\") < \"{}999999\".format(MAX_DATE))\n",
    "filtered_success = ping_success.filter(lambda p: p.get(\"payload/previousBuildId\") >= \"{}000000\".format(MIN_DATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the filtered RDDs to match between the different ping reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get an identifier that keeps in consideration both the current build\n",
    "# and the target build.\n",
    "ready_uuid = filtered_ready\\\n",
    "    .map(lambda p: (p.get(\"clientId\"),\n",
    "                    p.get(\"application/buildId\"),\n",
    "                    p.get(\"application/channel\"),\n",
    "                    p.get(\"application/version\"),\n",
    "                    p.get(\"payload/targetBuildId\"),\n",
    "                    p.get(\"payload/targetChannel\"),\n",
    "                    p.get(\"payload/targetVersion\")))\n",
    "\n",
    "# Get an identifier that considers both the prevous build info and the\n",
    "# current build info. The order of the values in the tuple need to match\n",
    "# the one from the previous RDD.\n",
    "success_uuid = filtered_success\\\n",
    "    .map(lambda p: (p.get(\"clientId\"),\n",
    "                    p.get(\"payload/previousBuildId\"),\n",
    "                    p.get(\"payload/previousChannel\"),\n",
    "                    p.get(\"payload/previousVersion\"),\n",
    "                    p.get(\"application/buildId\"),\n",
    "                    p.get(\"application/channel\"),\n",
    "                    p.get(\"application/version\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's match each `reason = ready` ping with a `reason = success` one, and count them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matching_update_pings = ready_uuid.intersection(success_uuid)\n",
    "matching_update_ping_count = matching_update_pings.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, show up some stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"{:.3f}% of the 'update' ping with reason 'ready' have a matching ping with reason 'success'.\"\\\n",
    "      .format(pct(matching_update_ping_count, filtered_ready.count())))\n",
    "print(\"{:.3f}% of the 'update' ping with reason 'success' have a matching ping with reason 'ready'.\"\\\n",
    "      .format(pct(matching_update_ping_count, filtered_success.count())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only ~63% of the update ping sent when an update is ready to be applied have a corrensponding ping that's sent, for the same client and upgrade path, after the update is successfully applied. One possible explaination for this is the delay with which updates get applied after they get downloaded: unless the browser is restarted (and that can happen after days due to user suspending their machines), we won't see the ready ping anytime soon. \n",
    "\n",
    "Roughly 89% of the `update` pings with `reason = success` can be traced back to an `update` with `reason = ready`. The missing ~10% matches can be due to users disabling automatic updates (see [this query](https://sql.telemetry.mozilla.org/queries/21667#103055)) and [other edge cases](https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/update-ping.html#expected-behaviours): no `update` ping is sent [in that case](https://bugzilla.mozilla.org/show_bug.cgi?id=1386619) if an update is manually triggered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}