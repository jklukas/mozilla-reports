{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Crash Ping Submission and Recording Delays - pingSender\"\n",
    "authors:\n",
    "- chutten\n",
    "tags:\n",
    "- crash ping\n",
    "- delay\n",
    "- pingSender\n",
    "created_at: 2017-03-07\n",
    "updated_at: 2017-03-07\n",
    "tldr: How long does it take before we get crash pings from users that have pingSender vs users who don't?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crash Ping Submission and Recording Delays - pingSender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is follow-up analysis to the [Crash Ping Submission and Recording Delays by Channel](http://reports.telemetry.mozilla.org/post/projects/crash_ping_delays.kp) analysis previously performed.\n",
    "\n",
    "Specifically, this one investigates the difference between typical values of \"recording delay\" and \"submission delay\" before and after [pingSender started sending pings](https://bugzilla.mozilla.org/show_bug.cgi?id=1310703)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ujson as json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "import IPython\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from email.utils import parsedate_tz, mktime_tz, formatdate\n",
    "\n",
    "from plotly.graph_objs import *\n",
    "from moztelemetry import get_pings_properties, get_one_ping_per_client\n",
    "from moztelemetry.dataset import Dataset\n",
    "\n",
    "%matplotlib inline\n",
    "IPython.core.pylabtools.figsize(16, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be looking at two cohorts: Feb 1-14 and Feb 16 - Mar 1. `pingSender` was released Feb 15. We will be limiting to crashes submitted by builds built during the cohort range that were submitted during the cohort range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_pings = Dataset.from_source(\"telemetry\") \\\n",
    "    .where(docType='crash') \\\n",
    "    .where(appUpdateChannel=\"nightly\") \\\n",
    "    .where(submissionDate=lambda x: x >= \"20170201\" and x < \"20170214\") \\\n",
    "    .where(appBuildId=lambda x: x >= \"20170201\" and x < \"20170214\") \\\n",
    "    .records(sc, sample=1)\n",
    "    \n",
    "post_pings = Dataset.from_source(\"telemetry\") \\\n",
    "    .where(docType='crash') \\\n",
    "    .where(appUpdateChannel=\"nightly\") \\\n",
    "    .where(submissionDate=lambda x: x >= \"20170216\" and x < \"20170301\") \\\n",
    "    .where(appBuildId=lambda x: x >= \"20170216\" and x < \"20170301\") \\\n",
    "    .records(sc, sample=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at delays, we need to look at times. There are a lot of times, and they are recorded relative to different clocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`creationDate`** - The time the Telemetry code in Firefox created the ping, according to the client's clock, expressed as an ISO string. **`meta/creationTimestamp`** is the same time, but expressed in nanoseconds since the epoch.\n",
    "\n",
    "**`meta/Date`** - The time the Telemetry code in Firefox sent the ping to the server, according to the client's clock, expressed as a Date string conforming to [RFC 7231](https://tools.ietf.org/html/rfc7231#section-7.1.1.1).\n",
    "\n",
    "**`meta/Timestamp`** - The time the ping was received by the server, according to the server's\n",
    "clock, expressed in nanoseconds since the epoch.\n",
    "\n",
    "**`payload/crashDate`** - Sadly the only time info associated with the crash event itself is at day resolution. I expect cliffs to show at multiples of 24 hours on the CDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_subset = get_pings_properties(pre_pings, [\"application/channel\",\n",
    "                                              \"id\",\n",
    "                                              \"payload/processType\",\n",
    "                                              \"creationDate\",\n",
    "                                              \"meta/creationTimestamp\",\n",
    "                                              \"meta/Date\",\n",
    "                                              \"meta/Timestamp\",\n",
    "                                              \"payload/crashDate\"])\n",
    "\n",
    "post_subset = get_pings_properties(post_pings, [\"application/channel\",\n",
    "                                               \"id\",\n",
    "                                               \"payload/processType\",\n",
    "                                               \"creationDate\",\n",
    "                                               \"meta/creationTimestamp\",\n",
    "                                               \"meta/Date\",\n",
    "                                               \"meta/Timestamp\",\n",
    "                                               \"payload/crashDate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the analysis is cleaner if we combine the two cohorts here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_pre(p):\n",
    "    p['pre'] = 'pre'\n",
    "    return p\n",
    "\n",
    "def add_post(p):\n",
    "    p['pre'] = 'post'\n",
    "    return p\n",
    "\n",
    "combined = pre_subset.map(add_pre).union(post_subset.map(add_post))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick normalization: ditch any ping that doesn't have a subsessionLength, creationTimestamp, or Timestamp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prev_count = combined.count()\n",
    "combined = combined.filter(lambda p:\\\n",
    "                       p[\"payload/crashDate\"] is not None\\\n",
    "                       and p[\"meta/Timestamp\"] is not None\\\n",
    "                       and p[\"meta/creationTimestamp\"] is not None)\n",
    "filtered_count = combined.count()\n",
    "print \"Filtered {} of {} pings ({:.2f}%)\".format(prev_count - filtered_count, prev_count, 100.0 * (prev_count - filtered_count) / prev_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pingSender` only submits \"crash\" pings for main-process crashes, so let's limit ourselves to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prev_count = combined.count()\n",
    "combined = combined.filter(lambda p: p[\"payload/processType\"] == \"main\")\n",
    "filtered_count = combined.count()\n",
    "print \"Filtered {} of {} pings ({:.2f}%)\".format(prev_count - filtered_count, prev_count, 100.0 * (prev_count - filtered_count) / prev_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deduplication\n",
    "We sometimes receive crash pings more than once (identical document ids). This is usually below 1%, but there was a [known issue](https://bugzilla.mozilla.org/show_bug.cgi?id=1345153) that can complicate measurement.\n",
    "\n",
    "So we'll dedupe here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_deduped = combined\\\n",
    "    .map(lambda p: (p[\"id\"], p))\\\n",
    "    .reduceByKey(lambda a, b: a if a[\"meta/Timestamp\"] < a[\"meta/Timestamp\"] else b)\\\n",
    "    .map(lambda pair: pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_count = combined.count()\n",
    "combined_deduped_count = combined_deduped.count()\n",
    "print \"Filtered {} of {} crash pings ({:.2f}%)\".format(combined_count - combined_deduped_count, combined_count, 100.0 * (combined_count - combined_deduped_count) / combined_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = combined_deduped.take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be plotting Cumulative Distribution Functions today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_DELAY_S = 60 * 60 * 96.0\n",
    "HOUR_IN_S = 60 * 60.0\n",
    "PRES = ['pre', 'post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_plot(title, max_x):\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Delay (hours)\")\n",
    "    plt.ylabel(\"% of pings\")\n",
    "\n",
    "    plt.xticks(range(0, int(max_x) + 1, 2))\n",
    "    plt.yticks(map(lambda y: y / 20.0, range(0, 21, 1)))\n",
    "\n",
    "    plt.ylim(0.0, 1.0)\n",
    "    plt.xlim(0.0, max_x)\n",
    "\n",
    "    plt.grid(True)\n",
    "\n",
    "def plot_cdf(data):\n",
    "    sortd = np.sort(data)\n",
    "    ys = np.arange(len(sortd))/float(len(sortd))\n",
    "\n",
    "    plt.plot(sortd, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_delays(p):\n",
    "    \n",
    "    created = datetime.fromtimestamp(p[\"meta/creationTimestamp\"] / 1000.0 / 1000.0 / 1000.0)\n",
    "    received = datetime.fromtimestamp(p[\"meta/Timestamp\"] / 1000.0 / 1000.0 / 1000.0)\n",
    "    sent = datetime.fromtimestamp(mktime_tz(parsedate_tz(p[\"meta/Date\"]))) if p[\"meta/Date\"] is not None else received\n",
    "    clock_skew = received - sent\n",
    "    \n",
    "    reporting_delay = (created.date() - datetime.strptime(p[\"payload/crashDate\"], \"%Y-%m-%d\").date()).total_seconds()\n",
    "    submission_delay = (received - created - clock_skew).total_seconds()\n",
    "    return (reporting_delay, submission_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delays_by_chan = combined_deduped.map(lambda p: (p[\"pre\"], calculate_delays(p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recording Delay\n",
    "\n",
    "**Recording Delay** is the time from when the data \"happens\" to the time we record it in a ping. \n",
    "\n",
    "Due to only having day-resolution time information about the crash, this will be approximate and might look weird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setup_plot(\"Recording Delay CDF\", MAX_DELAY_S / HOUR_IN_S)\n",
    "\n",
    "for pre in PRES:\n",
    "    plot_cdf(delays_by_chan\\\n",
    "             .filter(lambda d: d[0] == pre)\\\n",
    "             .map(lambda d: d[1][0] / HOUR_IN_S if d[1][0] < MAX_DELAY_S else MAX_DELAY_S / HOUR_IN_S)\\\n",
    "             .collect())\n",
    "    \n",
    "plt.legend(PRES, loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, more main-process \"crash\" pings are recorded more quickly with `pingSender`.\n",
    "\n",
    "The only reason this isn't 100% at 0 days is probably due to \"crash\" pings failing to be received when sent by pingSender. (it tries at most once to send a ping). We will have better information on pingSender's success rate when [it sends some identifying headers](https://bugzilla.mozilla.org/show_bug.cgi?id=1336360#c36)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Delay\n",
    "\n",
    "**Submission Delay** is the delay between the data being recorded on the client and it being received by our infrastructure. It is thought to be dominated by the length of time Firefox isn't open on a client's computer, though retransmission attempts and throttling can also contribute.\n",
    "\n",
    "Here we run into a problem with **clock skew**. Clients' clocks aren't guaranteed to align with our server's clock, so we cannot necessarily compare the two. Luckily, with [bug 1144778](https://bugzilla.mozilla.org/show_bug.cgi?id=1144778) we introduced an HTTP `Date` header which tells us what time the client's clock thinks it is when it is sending the data. Coupled with the `Timestamp` field recorded which is what time the server's clock thinks it is when it receives the data, we can subtract the more egregious examples of clock skew and get values that are closer to reality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setup_plot(\"Submission Delay CDF\", MAX_DELAY_S / HOUR_IN_S)\n",
    "\n",
    "for pre in PRES:\n",
    "    plot_cdf(delays_by_chan\\\n",
    "             .filter(lambda d: d[0] == pre)\\\n",
    "             .map(lambda d: d[1][1] / HOUR_IN_S if d[1][1] < MAX_DELAY_S else MAX_DELAY_S / HOUR_IN_S)\\\n",
    "             .collect())\n",
    "    \n",
    "plt.legend(PRES, loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did not expect any large difference in submission delay as, regardless of whether `pingSender` is doing it or `CrashManager` is doing it, we attempt to send main-process \"crash\" pings immediately upon creation.\n",
    "\n",
    "Likely the only reason this isn't 100% at 0 is because of failing the initial transmission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recording + Submission Delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, summing the delays together and graphing them we get..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setup_plot(\"Combined Delay CDF\", MAX_DELAY_S / HOUR_IN_S)\n",
    "\n",
    "for pre in PRES:\n",
    "    plot_cdf(delays_by_chan\\\n",
    "             .filter(lambda d: d[0] == pre)\\\n",
    "             .map(lambda d: (d[1][0] + d[1][1]) / HOUR_IN_S if (d[1][0] + d[1][1]) < MAX_DELAY_S else MAX_DELAY_S / HOUR_IN_S)\\\n",
    "             .collect())\n",
    "    \n",
    "plt.legend(PRES, loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of `pingSender` results in an improvement in main-process \"crash\" ping client delay."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}