{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Hardware Report for Windows 7 and Windows 10 users.\n",
    "authors:\n",
    "- Alessio Placitelli\n",
    "tags:\n",
    "- hardware report\n",
    "- windows\n",
    "created_at: 2017-04-05\n",
    "updated_at: 2017-04-05\n",
    "tldr: This is a one-off ETL job for getting separate hardware reports for users runing Windows 7 or Windows 10.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ujson as json\n",
    "import datetime as dt\n",
    "import os.path\n",
    "import boto3\n",
    "import botocore\n",
    "import calendar\n",
    "import requests\n",
    "import moztelemetry.standards as moz_std\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_json(uri):\n",
    "    \"\"\" Perform an HTTP GET on the given uri, return the results as json.\n",
    "    If there is an error fetching the data, raise an exception.\n",
    "    \n",
    "    Args:\n",
    "        uri: the string URI to fetch.\n",
    "    \n",
    "    Returns:\n",
    "        A JSON object with the response.\n",
    "    \"\"\"\n",
    "    data = requests.get(uri)\n",
    "    # Raise an exception if the fetch failed.\n",
    "    data.raise_for_status()\n",
    "    return data.json()\n",
    "\n",
    "def get_OS_arch(browser_arch, os_name, is_wow64):\n",
    "    \"\"\" Infers the OS arch from environment data.\n",
    "    \n",
    "    Args:\n",
    "        browser_arch: the browser architecture string (either \"x86\" or \"x86-64\").\n",
    "        os_name: the operating system name.\n",
    "        is_wow64: on Windows, indicates if the browser process is running under WOW64.\n",
    "    \n",
    "    Returns:\n",
    "        'x86' if the underlying OS is 32bit, 'x86-64' if it's a 64bit OS.\n",
    "    \"\"\"\n",
    "    \n",
    "    is_64bit_browser = browser_arch == 'x86-64'\n",
    "    # If it's a 64bit browser build, then we're on a 64bit system.\n",
    "    if is_64bit_browser:\n",
    "        return 'x86-64'\n",
    "    \n",
    "    is_windows = os_name == 'Windows_NT'\n",
    "    # If we're on Windows, with a 32bit browser build, and |isWow64 = true|,\n",
    "    # then we're on a 64 bit system.\n",
    "    if is_windows and is_wow64:\n",
    "        return 'x86-64'\n",
    "    \n",
    "    # Otherwise we're probably on a 32 bit system.\n",
    "    return 'x86'\n",
    "\n",
    "def vendor_name_from_id(id):\n",
    "    \"\"\" Get the string name matching the provided vendor id.\n",
    "    \n",
    "    Args:\n",
    "        id: A string containing the vendor id.\n",
    "    \n",
    "    Returns: \n",
    "        A string containing the vendor name or \"(Other <ID>)\" if\n",
    "        unknown.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: We need to make this an external resource for easier\n",
    "    # future updates.\n",
    "    vendor_map = {\n",
    "        '0x1013': 'Cirrus Logic',\n",
    "        '0x1002': 'AMD',\n",
    "        '0x8086': 'Intel',\n",
    "        '0x5333': 'S3 Graphics',\n",
    "        '0x1039': 'SIS',\n",
    "        '0x1106': 'VIA',\n",
    "        '0x10de': 'NVIDIA',\n",
    "        '0x102b': 'Matrox',\n",
    "        '0x15ad': 'VMWare',\n",
    "        '0x80ee': 'Oracle VirtualBox',\n",
    "        '0x1414': 'Microsoft Basic',\n",
    "    }\n",
    "    \n",
    "    return vendor_map.get(id, \"Other\")\n",
    "\n",
    "def get_device_family_chipset(vendor_id, device_id):\n",
    "    \"\"\" Get the family and chipset strings given the vendor and device ids.\n",
    "    \n",
    "    Args:\n",
    "        vendor_id: a string representing the vendor id (e.g. '0xabcd').\n",
    "        device_id: a string representing the device id (e.g. '0xbcde').\n",
    "    \n",
    "    Returns:\n",
    "        A string in the format \"Device Family Name-Chipset Name\".\n",
    "    \"\"\"\n",
    "    if not vendor_id in device_map:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    if not device_id in device_map[vendor_id]:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    return \"-\".join(device_map[vendor_id][device_id])\n",
    "\n",
    "def invert_device_map(m):\n",
    "    \"\"\" Inverts a GPU device map fetched from the jrmuizel's Github repo. \n",
    "    The layout of the fetched GPU map layout is:\n",
    "        Vendor ID -> Device Family -> Chipset -> [Device IDs]\n",
    "    We should convert it to:\n",
    "        Vendor ID -> Device ID -> [Device Family, Chipset]\n",
    "    \"\"\"\n",
    "    device_id_map = {}\n",
    "    for vendor, u in m.iteritems():\n",
    "        device_id_map['0x' + vendor] = {}\n",
    "        for family, v in u.iteritems():\n",
    "            for chipset, ids in v.iteritems():\n",
    "                device_id_map['0x' + vendor].update({('0x' + gfx_id): [family, chipset] for gfx_id in ids})\n",
    "    return device_id_map\n",
    "\n",
    "def build_device_map():\n",
    "    \"\"\" This function builds a dictionary that will help us mapping vendor/device ids to a \n",
    "    human readable device family and chipset name.\"\"\"\n",
    "\n",
    "    intel_raw = fetch_json(\"https://github.com/jrmuizel/gpu-db/raw/master/intel.json\")\n",
    "    nvidia_raw = fetch_json(\"https://github.com/jrmuizel/gpu-db/raw/master/nvidia.json\")\n",
    "    amd_raw = fetch_json(\"https://github.com/jrmuizel/gpu-db/raw/master/amd.json\")\n",
    "    \n",
    "    device_map = {}\n",
    "    device_map.update(invert_device_map(intel_raw))\n",
    "    device_map.update(invert_device_map(nvidia_raw))\n",
    "    device_map.update(invert_device_map(amd_raw))\n",
    "\n",
    "    return device_map\n",
    "    \n",
    "device_map = build_device_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to query the longitudinal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reasons why the data for a client can be discarded.\n",
    "REASON_INACTIVE = \"inactive\"\n",
    "REASON_BROKEN_DATA = \"broken\"\n",
    "\n",
    "def get_valid_client_record(r, data_index):\n",
    "    \"\"\" Check if the referenced record is sane or contains partial/broken data.\n",
    "    \n",
    "    Args:\n",
    "        r: The client entry in the longitudinal dataset.\n",
    "        dat_index: The index of the sample within the client record.\n",
    "    \n",
    "    Returns:\n",
    "        An object containing the client hardware data or REASON_BROKEN_DATA if the\n",
    "        data is invalid.\n",
    "    \"\"\"\n",
    "    gfx_adapters = r[\"system_gfx\"][data_index][\"adapters\"]\n",
    "    monitors = r[\"system_gfx\"][data_index][\"monitors\"]\n",
    "    \n",
    "    # We should make sure to have GFX adapter. If we don't, discard this record.\n",
    "    if not gfx_adapters or not gfx_adapters[0]:\n",
    "        return REASON_BROKEN_DATA\n",
    "    \n",
    "    # Due to bug 1175005, Firefox on Linux isn't sending the screen resolution data.\n",
    "    # Don't discard the rest of the ping for that: just set the resolution to 0 if\n",
    "    # unavailable. See bug 1324014 for context.\n",
    "    screen_width = 0\n",
    "    screen_height = 0\n",
    "    if monitors and monitors[0]:\n",
    "        screen_width = monitors[0][\"screen_width\"]\n",
    "        screen_height = monitors[0][\"screen_height\"]\n",
    "    \n",
    "    # Non Windows OS do not have that property.\n",
    "    is_wow64 = r[\"system\"][data_index][\"is_wow64\"] == True\n",
    "    \n",
    "    # At this point, we should have filtered out all the weirdness. Fetch\n",
    "    # the data we need. \n",
    "    data = {\n",
    "        'browser_arch': r[\"build\"][data_index][\"architecture\"],\n",
    "        'os_name': r[\"system_os\"][data_index][\"name\"],\n",
    "        'os_version': r[\"system_os\"][data_index][\"version\"],\n",
    "        'memory_mb': r[\"system\"][data_index][\"memory_mb\"],\n",
    "        'is_wow64': is_wow64,\n",
    "        'num_gfx_adapters': len(gfx_adapters),\n",
    "        'gfx0_vendor_id': gfx_adapters[0][\"vendor_id\"],\n",
    "        'gfx0_device_id': gfx_adapters[0][\"device_id\"],\n",
    "        'screen_width': screen_width,\n",
    "        'screen_height': screen_height,\n",
    "        'cpu_cores': r[\"system_cpu\"][data_index][\"cores\"],\n",
    "        'cpu_vendor': r[\"system_cpu\"][data_index][\"vendor\"],\n",
    "        'cpu_speed': r[\"system_cpu\"][data_index][\"speed_mhz\"],\n",
    "        'has_flash': False\n",
    "    }\n",
    "    \n",
    "    # The plugins data can still be null or empty, account for that.\n",
    "    plugins = r[\"active_plugins\"][data_index] if r[\"active_plugins\"] else None\n",
    "    if plugins:\n",
    "        data['has_flash'] = any([True for p in plugins if p['name'] == 'Shockwave Flash'])\n",
    "    \n",
    "    return REASON_BROKEN_DATA if None in data.values() else data\n",
    "\n",
    "def get_latest_valid_per_client(entry):\n",
    "    \"\"\" Get the most recently submitted ping for a client.\n",
    "\n",
    "    Then use this index to look up the data from the other columns (we can assume that the sizes\n",
    "    of these arrays match, otherwise the longitudinal dataset is broken).\n",
    "    Once we have the data, we make sure it's valid and return it.\n",
    "    \n",
    "    Args:\n",
    "        entry: The record containing all the data for a single client.\n",
    "\n",
    "    Returns:\n",
    "        An object containing the valid hardware data for the client or\n",
    "        REASON_BROKEN_DATA if it send broken data. \n",
    "    \n",
    "    Raises:\n",
    "        ValueError: if the columns within the record have mismatching lengths. This\n",
    "        means the longitudinal dataset is corrupted.\n",
    "    \"\"\"\n",
    "\n",
    "    # Some clients might be missing entire sections. If that's\n",
    "    # a basic section, skip them, we don't want partial data.\n",
    "    # Don't enforce the presence of \"active_plugins\", as it's not included\n",
    "    # by the pipeline if no plugin is reported by Firefox (see bug 1333806).\n",
    "    desired_sections = [\n",
    "        \"build\", \"system_os\", \"submission_date\", \"system\",\n",
    "        \"system_gfx\", \"system_cpu\"\n",
    "    ]\n",
    "\n",
    "    for field in desired_sections:\n",
    "        if entry[field] is None:\n",
    "            return REASON_BROKEN_DATA\n",
    "\n",
    "        # All arrays in the longitudinal dataset should have the same length, for a\n",
    "        # single client. If that's not the case, if our index is not there, throw.\n",
    "        if entry[field][0] is None:\n",
    "            raise ValueError(\"Null \" + field)\n",
    "\n",
    "    return get_valid_client_record(entry, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define how we transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_data(p):\n",
    "    \"\"\" This function prepares the data for further analyses (e.g. unit conversion,\n",
    "    vendor id to string, ...). \"\"\"\n",
    "    cpu_speed = round(p['cpu_speed'] / 1000.0, 1)\n",
    "    return {\n",
    "        'browser_arch': p['browser_arch'],\n",
    "        'cpu_cores': p['cpu_cores'],\n",
    "        'cpu_cores_speed': str(p['cpu_cores']) + '_' + str(cpu_speed),\n",
    "        'cpu_vendor': p['cpu_vendor'],\n",
    "        'cpu_speed': cpu_speed,\n",
    "        'num_gfx_adapters': p['num_gfx_adapters'],\n",
    "        'gfx0_vendor_name': vendor_name_from_id(p['gfx0_vendor_id']),\n",
    "        'gfx0_model': get_device_family_chipset(p['gfx0_vendor_id'], p['gfx0_device_id']),\n",
    "        'resolution': str(p['screen_width']) + 'x' + str(p['screen_height']),\n",
    "        'memory_gb': int(round(p['memory_mb'] / 1024.0)),\n",
    "        'os': p['os_name'] + '-' + p['os_version'],\n",
    "        'os_arch': get_OS_arch(p['browser_arch'], p['os_name'], p['is_wow64']),\n",
    "        'has_flash': p['has_flash']\n",
    "    }\n",
    "\n",
    "def aggregate_data(processed_data):\n",
    "    def seq(acc, v):\n",
    "        # The dimensions over which we want to aggregate the different values.\n",
    "        keys_to_aggregate = [\n",
    "            'browser_arch',\n",
    "            'cpu_cores',\n",
    "            'cpu_cores_speed',\n",
    "            'cpu_vendor',\n",
    "            'cpu_speed',\n",
    "            'num_gfx_adapters',\n",
    "            'gfx0_vendor_name',\n",
    "            'gfx0_model',\n",
    "            'resolution',\n",
    "            'memory_gb',\n",
    "            'os',\n",
    "            'os_arch',\n",
    "            'has_flash'\n",
    "        ]\n",
    "\n",
    "        for key_name in keys_to_aggregate:\n",
    "            # We want to know how many users have a particular configuration (e.g. using a particular\n",
    "            # cpu vendor). For each dimension of interest, build a key as (hw, value) and count its\n",
    "            # occurrences among the user base.\n",
    "            acc_key = (key_name, v[key_name])\n",
    "            acc[acc_key] = acc.get(acc_key, 0) + 1\n",
    "        \n",
    "        return acc\n",
    "\n",
    "    def cmb(v1, v2):\n",
    "        # Combine the counts from the two partial dictionaries. Hacky?\n",
    "        return  { k: v1.get(k, 0) + v2.get(k, 0) for k in set(v1) | set(v2) }\n",
    "    \n",
    "    return processed_data.aggregate({}, seq, cmb)\n",
    "\n",
    "def collapse_buckets(aggregated_data, count_threshold):\n",
    "    \"\"\" Collapse uncommon configurations in generic groups to preserve privacy.\n",
    "    \n",
    "    This takes the dictionary of aggregated results from |aggregate_data| and collapses\n",
    "    entries with a value less than |count_threshold| in a generic bucket.\n",
    "    \n",
    "    Args:\n",
    "        aggregated_data: The object containing aggregated data.\n",
    "        count_threhold: Groups (or \"configurations\") containing less than this value\n",
    "        are collapsed in a generic bucket.\n",
    "    \"\"\"\n",
    "    \n",
    "    # These fields have a fixed set of values and we need to report all of them.\n",
    "    EXCLUSION_LIST = [ \"has_flash\", \"browser_arch\", \"os_arch\" ]\n",
    "    \n",
    "    collapsed_groups = {}\n",
    "    for k,v in aggregated_data.iteritems():\n",
    "        key_type = k[0]\n",
    "        \n",
    "        # If the resolution is 0x0 (see bug 1324014), put that into the \"Other\"\n",
    "        # bucket.\n",
    "        if key_type == 'resolution' and k[1] == '0x0':\n",
    "            other_key = ('resolution', 'Other')\n",
    "            collapsed_groups[other_key] = collapsed_groups.get(other_key, 0) + v\n",
    "            continue\n",
    "    \n",
    "        # Don't clump this group into the \"Other\" bucket if it has enough\n",
    "        # users it in.\n",
    "        if v > count_threshold or key_type in EXCLUSION_LIST:\n",
    "            collapsed_groups[k] = v\n",
    "            continue\n",
    "        \n",
    "        # If we're here, it means that the key has not enough elements.\n",
    "        # Fall through the next cases and try to group things together.\n",
    "        new_group_key = 'Other'\n",
    "        \n",
    "        # Let's try to group similar resolutions together.\n",
    "        if key_type == 'resolution':\n",
    "            # Extract the resolution.\n",
    "            [w, h] = k[1].split('x')\n",
    "            # Round to the nearest hundred.\n",
    "            w = int(round(int(w), -2))\n",
    "            h = int(round(int(h), -2))\n",
    "            # Build up a new key.\n",
    "            new_group_key = '~' + str(w) + 'x' + str(h)\n",
    "        elif key_type == 'os':\n",
    "            [os, ver] = k[1].split('-', 1)\n",
    "            new_group_key = os + '-' + 'Other'\n",
    "        \n",
    "        # We don't have enough data for this particular group/configuration.\n",
    "        # Aggregate it with the data in the \"Other\" bucket\n",
    "        other_key = (k[0], new_group_key)\n",
    "        collapsed_groups[other_key] = collapsed_groups.get(other_key, 0) + v\n",
    "    \n",
    "    # The previous grouping might have created additional groups. Let's check again.\n",
    "    final_groups = {}\n",
    "    for k,v in collapsed_groups.iteritems():\n",
    "        # Don't clump this group into the \"Other\" bucket if it has enough\n",
    "        # users it in.\n",
    "        if (v > count_threshold and k[1] != 'Other') or k[0] in EXCLUSION_LIST:\n",
    "            final_groups[k] = v\n",
    "            continue\n",
    "\n",
    "        # We don't have enough data for this particular group/configuration.\n",
    "        # Aggregate it with the data in the \"Other\" bucket\n",
    "        other_key = (k[0], 'Other')\n",
    "        final_groups[other_key] = final_groups.get(other_key, 0) + v\n",
    "    \n",
    "    return final_groups\n",
    "\n",
    "\n",
    "def finalize_data(data, sample_count, broken_ratio):\n",
    "    \"\"\" Finalize the aggregated data.\n",
    "    \n",
    "    Translate raw sample numbers to percentages and add the date for the reported\n",
    "    week along with the percentage of discarded samples due to broken data.\n",
    "    \n",
    "    Rename the keys to more human friendly names.\n",
    "    \n",
    "    Args:\n",
    "        data: Data in aggregated form.\n",
    "        sample_count: The number of samples the aggregates where generated from.\n",
    "        broken_ratio: The percentage of samples discarded due to broken data.\n",
    "        inactive_ratio: The percentage of samples discarded due to the client not sending data.\n",
    "        report_date: The starting day for the reported week.\n",
    "    \n",
    "    Returns:\n",
    "        An object containing the reported hardware statistics.\n",
    "    \"\"\"\n",
    "\n",
    "    denom = float(sample_count)\n",
    "\n",
    "    aggregated_percentages = {\n",
    "        'broken': broken_ratio,\n",
    "    }\n",
    "\n",
    "    keys_translation = {\n",
    "        'browser_arch': 'browserArch_',\n",
    "        'cpu_cores': 'cpuCores_',\n",
    "        'cpu_cores_speed': 'cpuCoresSpeed_',\n",
    "        'cpu_vendor': 'cpuVendor_',\n",
    "        'cpu_speed': 'cpuSpeed_',\n",
    "        'num_gfx_adapters': 'gpuNum_',\n",
    "        'gfx0_vendor_name': 'gpuVendor_',\n",
    "        'gfx0_model': 'gpuModel_',\n",
    "        'resolution': 'resolution_',\n",
    "        'memory_gb': 'ram_',\n",
    "        'os': 'osName_',\n",
    "        'os_arch': 'osArch_',\n",
    "        'has_flash': 'hasFlash_'\n",
    "    }\n",
    "\n",
    "    # Compute the percentages from the raw numbers.\n",
    "    for k, v in data.iteritems():\n",
    "        # The old key is a tuple (key, value). We translate the key part and concatenate the\n",
    "        # value as a string.\n",
    "        new_key = keys_translation[k[0]] + unicode(k[1])\n",
    "        aggregated_percentages[new_key] = v / denom\n",
    "\n",
    "    return aggregated_percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the report\n",
    "We compute the hardware report for users running Windows 7 or Windows 10 by taking the most recent data available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to the longitudinal dataset and get a subset of the columns\n",
    "sqlQuery = \"SELECT \" +\\\n",
    "           \"build,\" +\\\n",
    "           \"client_id,\" +\\\n",
    "           \"active_plugins,\" +\\\n",
    "           \"system_os,\" +\\\n",
    "           \"submission_date,\" +\\\n",
    "           \"system,\" +\\\n",
    "           \"system_gfx,\" +\\\n",
    "           \"system_cpu,\" +\\\n",
    "           \"normalized_channel \" +\\\n",
    "           \"FROM longitudinal\"\n",
    "frame = sqlContext.sql(sqlQuery)\\\n",
    "                  .where(\"normalized_channel = 'release'\")\\\n",
    "                  .where(\"system_os is not null and system_os[0].name = 'Windows_NT'\")\\\n",
    "                  .where(\"build is not null and build[0].application_name = 'Firefox'\")\n",
    "\n",
    "\n",
    "# The number of all the fetched records (including inactive and broken).\n",
    "records_count = frame.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the most recent, valid data for each client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = frame.rdd.map(lambda r: get_latest_valid_per_client(r))\n",
    "\n",
    "# Filter out broken data.\n",
    "filtered_data = data.filter(lambda r: r is not REASON_BROKEN_DATA)\n",
    "\n",
    "# Count the broken records\n",
    "broken_count = data.filter(lambda r: r is REASON_BROKEN_DATA).count()\n",
    "print(\"Found {} broken records.\".format(broken_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the data\n",
    "This extracts the relevant information from each valid data unit returned from the previous step. Each *processed_data* entry represents a single user machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processed_data = filtered_data.map(prepare_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processed_data.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate the data for Windows 7 and Windows 10\n",
    "Aggregate the machine configurations in a more digestible form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aggregate the data for Windows 7 (Windows NT version 6.1)\n",
    "windows7_data = processed_data.filter(lambda p: p.get(\"os\") == \"Windows_NT-6.1\")\n",
    "aggregated_w7 = aggregate_data(windows7_data)\n",
    "windows7_count = windows7_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Aggregate the data for Windows 10 (Windows NT version 10.0)\n",
    "windows10_data = processed_data.filter(lambda p: p.get(\"os\") == \"Windows_NT-10.0\")\n",
    "aggregated_w10 = aggregate_data(windows10_data)\n",
    "windows10_count = windows10_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collapse together groups that count less than 1% of our samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_records_count = records_count - broken_count\n",
    "threshold_to_collapse = int(valid_records_count * 0.01)\n",
    "\n",
    "print \"Collapsing smaller groups into the other bucket (threshold {th})\".format(th=threshold_to_collapse)\n",
    "collapsed_w7 = collapse_buckets(aggregated_w7, threshold_to_collapse)\n",
    "collapsed_w10 = collapse_buckets(aggregated_w10, threshold_to_collapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump the aggregates to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "broken_ratio = broken_count / float(records_count)\n",
    "\n",
    "w7_json = finalize_data(collapsed_w7, windows7_count, broken_ratio)\n",
    "json_entry = json.dumps(w7_json)\n",
    "with open(\"w7data.json\", \"w\") as json_file:\n",
    "    json_file.write(\"[\" + json_entry.encode('utf8') + \"]\\n\")\n",
    "    \n",
    "    \n",
    "w10_json = finalize_data(collapsed_w10, windows10_count, broken_ratio)\n",
    "json_entry = json.dumps(w10_json)\n",
    "with open(\"w10data.json\", \"w\") as json_file:\n",
    "    json_file.write(\"[\" + json_entry.encode('utf8') + \"]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}